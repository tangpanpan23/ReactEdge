package ai

import (
	"bytes"
	"context"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"strings"
	"sync"
	"time"

	"github.com/sashabaranov/go-openai"
)

// Client AIæœåŠ¡å®¢æˆ·ç«¯æ¥å£
type Client interface {
	// åŸºç¡€æ–¹æ³•
	GetProvider() ProviderType
	GetAvailableModels() []string
	ValidateModel(model string) bool

	// æ ¸å¿ƒAIåŠŸèƒ½
	AnalyzeImage(ctx context.Context, imageURL, prompt string) (*ImageAnalysisResult, error)
	GenerateQuestions(ctx context.Context, contextInfo string, category string) ([]Question, error)
	PolishNote(ctx context.Context, rawContent, contextInfo string) (*PolishedNote, error)
	TextToSpeech(ctx context.Context, text, voice, language string, speed float64) ([]byte, string, error)
	AnalyzeVideo(ctx context.Context, videoData []byte, format, analysisType string, duration float64) (*VideoAnalysis, error)
	GenerateVideo(ctx context.Context, script, style string, duration float64, scenes []string, voice, language string) ([]byte, string, float64, *VideoMetadata, error)

	// ReactEdgeç‰¹å®šåŠŸèƒ½
	GenerateReactionTemplates(ctx context.Context, scenario, style string) ([]ReactionTemplate, error)
	AnalyzeExpressionStyle(ctx context.Context, personName string, sampleText string) (*StyleAnalysis, error)
	SimulateDebate(ctx context.Context, scenario string, difficulty int, userStyle string) (*DebateSimulation, error)
	EvaluateReaction(ctx context.Context, userResponse, scenario, expectedStyle string) (*ReactionEvaluation, error)
}

// BaseClient åŸºç¡€AIå®¢æˆ·ç«¯ç»“æ„ä½“
type BaseClient struct {
	provider ProviderType
	config   *Config
}

// GetProvider è·å–æœåŠ¡å•†ç±»å‹
func (c *BaseClient) GetProvider() ProviderType {
	return c.provider
}

// NewClient åˆ›å»ºAIå®¢æˆ·ç«¯
func NewClient(provider ProviderType, config *Config) (Client, error) {
	switch provider {
	case ProviderTAL:
		return NewTALClient(config.TAL)
	case ProviderOpenAI:
		return NewOpenAIClient(config.OpenAI)
	case ProviderClaude:
		return NewClaudeClient(config.Claude)
	case ProviderAzure:
		return NewAzureClient(config.Azure)
	case ProviderBaidu:
		return NewBaiduClient(config.Baidu)
	case ProviderSpark:
		return NewSparkClient(config.Spark)
	default:
		return nil, fmt.Errorf("ä¸æ”¯æŒçš„æœåŠ¡å•†: %s", provider)
	}
}

// TALClient TALå†…éƒ¨AIæœåŠ¡å®¢æˆ·ç«¯
type TALClient struct {
	*BaseClient
	httpClient *http.Client
	config     *TALConfig
	baseURL    string
	authToken  string
	client     *openai.Client // OpenAIå…¼å®¹å®¢æˆ·ç«¯

	// è¯·æ±‚é™æµ
	requestMutex   sync.Mutex
	lastRequestTime time.Time
	minInterval     time.Duration // æœ€å°è¯·æ±‚é—´éš”
}

// NewTALClient åˆ›å»ºTALå®¢æˆ·ç«¯
func NewTALClient(config TALConfig) (*TALClient, error) {
	// æ„å»ºè®¤è¯token
	authToken := fmt.Sprintf("%s:%s", config.TAL_MLOPS_APP_ID, config.TAL_MLOPS_APP_KEY)

	// ä»é…ç½®ä¸­è·å–è¯·æ±‚é—´éš”ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤å€¼
	minInterval := 1 * time.Second // é»˜è®¤1ç§’
	if config.Timeout > 0 {
		// å¯ä»¥æ ¹æ®é…ç½®è°ƒæ•´é—´éš”ï¼Œè¿™é‡Œæš‚æ—¶ä¿æŒé»˜è®¤
		minInterval = 1 * time.Second
	}

	fmt.Printf("ğŸ”§ åˆå§‹åŒ–TAL AIå®¢æˆ·ç«¯ - ç«¯ç‚¹: %s, æœ€å°è¯·æ±‚é—´éš”: %.1fç§’\n", config.BaseURL, minInterval.Seconds())

	// æµ‹è¯•ç½‘ç»œè¿æ¥
	fmt.Printf("ğŸ” æµ‹è¯•TAL AIæœåŠ¡è¿æ¥...\n")
	testClient := &http.Client{Timeout: 10 * time.Second}
	testURL := config.BaseURL + "/models"
	testReq, _ := http.NewRequest("GET", testURL, nil)
	testReq.Header.Set("Authorization", fmt.Sprintf("Bearer %s", authToken))

	if testResp, testErr := testClient.Do(testReq); testErr == nil {
		testResp.Body.Close()
		fmt.Printf("âœ… TAL AIæœåŠ¡è¿æ¥æ­£å¸¸ (çŠ¶æ€ç : %d)\n", testResp.StatusCode)
	} else {
		fmt.Printf("âš ï¸ TAL AIæœåŠ¡è¿æ¥æµ‹è¯•å¤±è´¥: %v\n", testErr)
		fmt.Println("ğŸ’¡ å¯èƒ½çš„åŸå› : ç½‘ç»œè¿æ¥é—®é¢˜ã€æœåŠ¡ä¸å¯ç”¨æˆ–è®¤è¯ä¿¡æ¯é”™è¯¯")
	}

	// è®¾ç½®å†…éƒ¨AIæœåŠ¡ç«¯ç‚¹
	baseURL := config.BaseURL
	if baseURL == "" {
		baseURL = "http://ai-service.tal.com/openai-compatible/v1"
	}

	// åˆ›å»ºHTTPå®¢æˆ·ç«¯ - ä¸è®¾ç½®è¶…æ—¶ï¼Œå®Œå…¨ä¾èµ–ä¼ å…¥çš„contextæ§åˆ¶è¶…æ—¶
	httpClient := &http.Client{}

	fmt.Printf("ğŸ”§ HTTPå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆï¼Œè¶…æ—¶ç”±contextæ§åˆ¶\n")

	// åˆå§‹åŒ–OpenAIå…¼å®¹å®¢æˆ·ç«¯
	openaiConfig := openai.DefaultConfig(authToken)
	openaiConfig.BaseURL = baseURL
	client := openai.NewClientWithConfig(openaiConfig)

	return &TALClient{
		BaseClient: &BaseClient{
			provider: ProviderTAL,
			config:   &Config{TAL: config},
		},
		httpClient:     httpClient,
		config:         &config,
		baseURL:        baseURL,
		authToken:      authToken,
		client:         client,
		minInterval:    minInterval, // æ¯ç§’æœ€å¤š1ä¸ªè¯·æ±‚
		lastRequestTime: time.Now().Add(-minInterval * 2), // åˆå§‹åŒ–ä¸ºè¿‡å»çš„æ—¶é—´
	}, nil
}

// TALTransport TALè®¤è¯ä¼ è¾“å±‚
type TALTransport struct {
	base  http.RoundTripper
	token string
}

func (t *TALTransport) RoundTrip(req *http.Request) (*http.Response, error) {
	req.Header.Set("Authorization", t.token)
	if t.base == nil {
		return http.DefaultTransport.RoundTrip(req)
	}
	return t.base.RoundTrip(req)
}

// GetAvailableModels è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
func (c *TALClient) GetAvailableModels() []string {
	return []string{
		"qwen3-vl-plus",               // å›¾åƒåˆ†æä¸»æ¨¡å‹
		"qwen-flash",                  // æ–‡æœ¬ç”Ÿæˆä¸»æ¨¡å‹
		"qwen-flash",                  // å¤æ‚æ¨ç†ä¸»æ¨¡å‹ï¼ˆæ›´ç¨³å®šï¼‰
		"qwen3-omni-flash",            // è¯­éŸ³äº¤äº’ä¸»æ¨¡å‹
		"qwen3-vl-235b-a22b-instruct", // å›¾åƒåˆ†æå¤‡ç”¨æ¨¡å‹
		"qwen-turbo",                  // æ–‡æœ¬ç”Ÿæˆå¤‡ç”¨æ¨¡å‹
		"qwen-max",                    // å¤æ‚æ¨ç†å¤‡ç”¨æ¨¡å‹
	}
}

// ValidateModel éªŒè¯æ¨¡å‹æ˜¯å¦å¯ç”¨
func (c *TALClient) ValidateModel(model string) bool {
	availableModels := c.GetAvailableModels()
	for _, availableModel := range availableModels {
		if availableModel == model {
			return true
		}
	}
	return false
}

// GetModelForTask æ ¹æ®ä»»åŠ¡è·å–æ¨¡å‹
func (c *TALClient) GetModelForTask(task string) string {
	switch task {
	case "image_analysis":
		return c.config.Models.ImageAnalysis
	case "text_generation":
		return c.config.Models.TextGeneration
	case "advanced_reasoning":
		return c.config.Models.AdvancedReasoning
	case "voice_interaction":
		return c.config.Models.VoiceInteraction
	case "video_analysis":
		return c.config.Models.VideoAnalysis
	case "video_generation":
		return c.config.Models.VideoGeneration
	default:
		return c.config.Models.TextGeneration
	}
}

// AnalyzeImage å›¾åƒåˆ†æ
func (c *TALClient) AnalyzeImage(ctx context.Context, imageURL, prompt string) (*ImageAnalysisResult, error) {
	model := c.GetModelForTask("image_analysis")

	contentParts := []openai.ChatMessagePart{
		{
			Type: openai.ChatMessagePartTypeText,
			Text: prompt,
		},
		{
			Type: openai.ChatMessagePartTypeImageURL,
			ImageURL: &openai.ChatMessageImageURL{
				URL: imageURL,
			},
		},
	}

	req := openai.ChatCompletionRequest{
		Model: model,
		Messages: []openai.ChatCompletionMessage{
			{
				Role:         openai.ChatMessageRoleUser,
				MultiContent: contentParts,
			},
		},
		MaxTokens:   c.config.MaxTokens,
		Temperature: c.config.Temperature,
	}

	resp, err := c.client.CreateChatCompletion(ctx, req)
	if err != nil {
		// AIæœåŠ¡ä¸å¯ç”¨æ—¶ï¼Œè¿”å›é»˜è®¤å“åº”
		return getDefaultImageAnalysis(), nil
	}

	if len(resp.Choices) == 0 {
		return getDefaultImageAnalysis(), nil
	}

	content := resp.Choices[0].Message.Content

	result := &ImageAnalysisResult{
		ObjectName:     extractObjectName(content),
		Category:       extractCategory(content),
		Description:    content,
		Confidence:     0.95,
		KeyFeatures:    extractKeyFeatures(content),
		ScientificName: extractScientificName(content),
	}

	return result, nil
}

// GenerateQuestions ç”Ÿæˆé—®é¢˜
func (c *TALClient) GenerateQuestions(ctx context.Context, contextInfo string, category string) ([]Question, error) {
	model := c.GetModelForTask("text_generation")

	prompt := fmt.Sprintf(`åŸºäºä»¥ä¸‹ä¿¡æ¯ä¸ºç”¨æˆ·ç”Ÿæˆ3ä¸ªå¼•å¯¼æ€§çš„ååº”è®­ç»ƒé—®é¢˜ï¼š

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š%s
è®­ç»ƒç±»åˆ«ï¼š%s

è¦æ±‚ï¼š
1. é—®é¢˜è¦é€‚åˆèŒåœºæ²Ÿé€šåœºæ™¯
2. é—®é¢˜è¦æ¿€å‘æ€è€ƒå’Œååº”èƒ½åŠ›
3. é—®é¢˜éš¾åº¦è¦å¾ªåºæ¸è¿›ï¼ˆä»ç®€å•åˆ°æ·±å…¥ï¼‰
4. æ¯ä¸ªé—®é¢˜éƒ½è¦æœ‰æ˜ç¡®çš„ç±»å‹æ ‡æ³¨
5. ç¡®ä¿æ‰€æœ‰å†…å®¹é€‚åˆèŒåœºåŸ¹è®­åœºæ™¯

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- content: é—®é¢˜å†…å®¹
- type: é—®é¢˜ç±»å‹ï¼ˆscenarioåœºæ™¯, strategyç­–ç•¥, evaluationè¯„ä¼°ï¼‰
- difficulty: éš¾åº¦ï¼ˆbasicåŸºæœ¬, intermediateä¸­çº§, advancedé«˜çº§ï¼‰
- purpose: é—®é¢˜ç›®çš„è¯´æ˜`, contextInfo, category)

	req := openai.ChatCompletionRequest{
		Model: model,
		Messages: []openai.ChatCompletionMessage{
			{
				Role:    openai.ChatMessageRoleSystem,
				Content: "ä½ æ˜¯ä¸€ä¸ªèŒåœºæ²Ÿé€šè®­ç»ƒåŠ©æ‰‹ï¼Œä¸“é—¨ä¸ºç”¨æˆ·è®¾è®¡ååº”è®­ç»ƒé—®é¢˜ã€‚è¯·ä»¥JSONæ ¼å¼è¿”å›åŒ…å«questionsæ•°ç»„çš„ç»“æœã€‚",
			},
			{
				Role:    openai.ChatMessageRoleUser,
				Content: prompt,
			},
		},
		MaxTokens:   c.config.MaxTokens,
		Temperature: c.config.Temperature,
	}

	resp, err := c.client.CreateChatCompletion(ctx, req)
	if err != nil {
		return getDefaultQuestions(), nil
	}

	if len(resp.Choices) == 0 {
		return getDefaultQuestions(), nil
	}

	content := resp.Choices[0].Message.Content
	questions := parseQuestionsFromJSON(content)
	if len(questions) == 0 {
		return getDefaultQuestions(), nil
	}

	return questions, nil
}

// PolishNote æ¶¦è‰²ç¬”è®°ï¼ˆè¿™é‡Œç”¨äºæ¶¦è‰²ååº”è®°å½•ï¼‰
func (c *TALClient) PolishNote(ctx context.Context, rawContent, contextInfo string) (*PolishedNote, error) {
	model := c.GetModelForTask("text_generation")

	prompt := fmt.Sprintf(`è¯·å¸®ç”¨æˆ·æ¶¦è‰²ä»–ä»¬çš„ååº”è®­ç»ƒè®°å½•ï¼Œè®©å®ƒæ›´æ¸…æ™°ã€æœ‰é€»è¾‘æ€§ã€‚

åŸå§‹å†…å®¹ï¼š%s

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š%s

è¦æ±‚ï¼š
1. ä¿æŒç”¨æˆ·çš„åŸæ„å’Œè¡¨è¾¾ç‰¹è‰²
2. è®©è¡¨è¾¾æ›´æ¸…æ™°å‡†ç¡®
3. æ·»åŠ é€‚å½“çš„æ²Ÿé€šæŠ€å·§è§£é‡Š
4. æŒ‡å‡ºå¯èƒ½çš„æ”¹è¿›æ–¹å‘
5. ç¡®ä¿æ‰€æœ‰å†…å®¹é€‚åˆèŒåœºåŸ¹è®­åœºæ™¯

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼š

{
  "title": "è®°å½•æ ‡é¢˜",
  "summary": "å†…å®¹æ€»ç»“",
  "key_points": ["å…³é”®è¦ç‚¹1", "å…³é”®è¦ç‚¹2"],
  "communication_tips": ["æ²Ÿé€šæŠ€å·§1"],
  "questions": ["é—®é¢˜1"],
  "improvements": ["æ”¹è¿›å»ºè®®1"],
  "formatted_text": "æ ¼å¼åŒ–çš„æ–‡æœ¬å†…å®¹"
}

è¯·ç¡®ä¿è¿”å›çš„æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚`, rawContent, contextInfo)

	req := openai.ChatCompletionRequest{
		Model: model,
		Messages: []openai.ChatCompletionMessage{
			{
				Role:    openai.ChatMessageRoleUser,
				Content: prompt,
			},
		},
		MaxTokens:   c.config.MaxTokens,
		Temperature: c.config.Temperature,
	}

	resp, err := c.client.CreateChatCompletion(ctx, req)
	if err != nil {
		return getDefaultPolishedNote(), nil
	}

	if len(resp.Choices) == 0 {
		return getDefaultPolishedNote(), nil
	}

	content := resp.Choices[0].Message.Content

	// å¤„ç†markdownæ ¼å¼çš„JSONä»£ç å—
	jsonContent := content
	if strings.Contains(content, "```json") {
		startIndex := strings.Index(content, "```json")
		if startIndex != -1 {
			startIndex += 7
			endIndex := strings.Index(content[startIndex:], "```")
			if endIndex != -1 {
				jsonContent = strings.TrimSpace(content[startIndex : startIndex+endIndex])
			}
		}
	}

	var jsonResult PolishedNote
	if err := json.Unmarshal([]byte(jsonContent), &jsonResult); err != nil {
		jsonResult = PolishedNote{
			Title:       "ååº”è®­ç»ƒè®°å½•",
			Summary:     extractSummaryFromText(jsonContent),
			FormattedText: jsonContent,
			KeyPoints:   extractKeyPointsFromText(jsonContent),
		}
	}

	// ç¡®ä¿å¿…éœ€å­—æ®µæœ‰å€¼
	if jsonResult.Title == "" {
		jsonResult.Title = "ååº”è®­ç»ƒè®°å½•"
	}
	if jsonResult.Summary == "" {
		jsonResult.Summary = "è¿™æ˜¯ååº”è®­ç»ƒçš„è®°å½•æ€»ç»“"
	}
	if len(jsonResult.KeyPoints) == 0 {
		jsonResult.KeyPoints = []string{"è®°å½•äº†è®­ç»ƒè¿‡ç¨‹", "æ€»ç»“äº†ç»éªŒæ•™è®­"}
	}
	if jsonResult.FormattedText == "" {
		jsonResult.FormattedText = content
	}

	return &jsonResult, nil
}

// TextToSpeech æ–‡å­—è½¬è¯­éŸ³
func (c *TALClient) TextToSpeech(ctx context.Context, text, voice, language string, speed float64) ([]byte, string, error) {
	model := c.GetModelForTask("voice_interaction")

	prompt := fmt.Sprintf(`è¯·å°†ä»¥ä¸‹æ–‡å­—è½¬æ¢ä¸ºè¯­éŸ³ï¼š

æ–‡å­—å†…å®¹ï¼š%s
è¯­éŸ³ç±»å‹ï¼š%s
è¯­è¨€ï¼š%s
è¯­é€Ÿï¼š%.1få€é€Ÿ

è¦æ±‚ï¼š
1. ç”Ÿæˆè‡ªç„¶æµç•…çš„è¯­éŸ³
2. ä¿æŒä¸“ä¸šè¯­è°ƒ
3. è¯­é€Ÿé€‚ä¸­ï¼Œæ˜“äºç†è§£
4. å‘éŸ³å‡†ç¡®ï¼Œè¡¨è¾¾æ¸…æ™°

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼š
{
  "audio_data": "base64ç¼–ç çš„éŸ³é¢‘æ•°æ®",
  "format": "wav"
}

ä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼Œåªè¿”å›æœ‰æ•ˆçš„JSONã€‚`, text, voice, language, speed)

	req := openai.ChatCompletionRequest{
		Model: model,
		Messages: []openai.ChatCompletionMessage{
			{
				Role:    openai.ChatMessageRoleUser,
				Content: prompt,
			},
		},
		MaxTokens:   c.config.MaxTokens,
		Temperature: c.config.Temperature,
	}

	resp, err := c.client.CreateChatCompletion(ctx, req)
	if err != nil {
		return getDefaultAudioData(), "wav", nil
	}

	if len(resp.Choices) == 0 {
		return getDefaultAudioData(), "wav", nil
	}

	content := resp.Choices[0].Message.Content

	// å¤„ç†éŸ³é¢‘æ•°æ®
	var audioResult struct {
		AudioData string `json:"audio_data"`
		Format    string `json:"format"`
	}

	jsonContent := content
	if strings.Contains(content, "```json") {
		startIndex := strings.Index(content, "```json")
		if startIndex != -1 {
			startIndex += 7
			endIndex := strings.Index(content[startIndex:], "```")
			if endIndex != -1 {
				jsonContent = strings.TrimSpace(content[startIndex : startIndex+endIndex])
			}
		}
	}

	if err := json.Unmarshal([]byte(jsonContent), &audioResult); err != nil {
		return getDefaultAudioData(), "wav", nil
	}

	if audioResult.AudioData == "" {
		return getDefaultAudioData(), "wav", nil
	}

	audioBytes, err := base64.StdEncoding.DecodeString(audioResult.AudioData)
	if err != nil {
		return getDefaultAudioData(), "wav", nil
	}

	format := audioResult.Format
	if format == "" {
		format = "wav"
	}

	return audioBytes, format, nil
}

// AnalyzeVideo è§†é¢‘åˆ†æ
func (c *TALClient) AnalyzeVideo(ctx context.Context, videoData []byte, format, analysisType string, duration float64) (*VideoAnalysis, error) {
	// ç®€åŒ–å®ç°ï¼Œä½¿ç”¨é»˜è®¤åˆ†æç»“æœ
	return getDefaultVideoAnalysis(), nil
}

// GenerateVideo è§†é¢‘ç”Ÿæˆ
func (c *TALClient) GenerateVideo(ctx context.Context, script, style string, duration float64, scenes []string, voice, language string) ([]byte, string, float64, *VideoMetadata, error) {
	// ç®€åŒ–å®ç°ï¼Œè¿”å›æ¨¡æ‹Ÿè§†é¢‘æ•°æ®
	return c.generateMockVideo(script, style, duration, scenes, voice, language)
}

// GenerateReactionTemplates ç”Ÿæˆååº”æ¨¡æ¿
func (c *TALClient) GenerateReactionTemplates(ctx context.Context, scenario, style string) ([]ReactionTemplate, error) {
	model := c.GetModelForTask("text_generation")

	prompt := fmt.Sprintf(`åŸºäºä»¥ä¸‹åœºæ™¯å’Œé£æ ¼ï¼Œä¸ºç”¨æˆ·ç”Ÿæˆä¸´åœºååº”è®­ç»ƒæ¨¡æ¿ï¼š

åœºæ™¯ï¼š%s
é£æ ¼ï¼š%s

è¦æ±‚ï¼š
1. ç”Ÿæˆ3-5ä¸ªå®ç”¨çš„ååº”æ¨¡æ¿
2. æ¯ä¸ªæ¨¡æ¿åŒ…å«è§¦å‘æƒ…å¢ƒã€ååº”æ­¥éª¤ã€å…³é”®è¯æœ¯
3. æ¨¡æ¿è¦è´´åˆèŒåœºå®é™…åœºæ™¯
4. é£æ ¼è¦ç¬¦åˆæŒ‡å®šçš„æ²Ÿé€šé£æ ¼

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼ŒåŒ…å«templatesæ•°ç»„ï¼Œæ¯ä¸ªæ¨¡æ¿åŒ…å«ï¼š
- scenario: è§¦å‘æƒ…å¢ƒ
- steps: ååº”æ­¥éª¤æ•°ç»„
- key_phrases: å…³é”®è¯æœ¯æ•°ç»„
- style_notes: é£æ ¼è¦ç‚¹`, scenario, style)

	req := openai.ChatCompletionRequest{
		Model: model,
		Messages: []openai.ChatCompletionMessage{
			{
				Role:    openai.ChatMessageRoleSystem,
				Content: "ä½ æ˜¯ä¸€ä¸ªèŒåœºæ²Ÿé€šæ•™ç»ƒï¼Œä¸“é—¨è®¾è®¡ä¸´åœºååº”è®­ç»ƒæ¨¡æ¿ã€‚",
			},
			{
				Role:    openai.ChatMessageRoleUser,
				Content: prompt,
			},
		},
		MaxTokens:   c.config.MaxTokens,
		Temperature: c.config.Temperature,
	}

	resp, err := c.client.CreateChatCompletion(ctx, req)
	if err != nil {
		return getDefaultReactionTemplates(), nil
	}

	if len(resp.Choices) == 0 {
		return getDefaultReactionTemplates(), nil
	}

	content := resp.Choices[0].Message.Content

	// è§£æJSONå“åº”
	var result struct {
		Templates []ReactionTemplate `json:"templates"`
	}

	jsonContent := content
	if strings.Contains(content, "```json") {
		startIndex := strings.Index(content, "```json")
		if startIndex != -1 {
			startIndex += 7
			endIndex := strings.Index(content[startIndex:], "```")
			if endIndex != -1 {
				jsonContent = strings.TrimSpace(content[startIndex : startIndex+endIndex])
			}
		}
	}

	if err := json.Unmarshal([]byte(jsonContent), &result); err != nil {
		return getDefaultReactionTemplates(), nil
	}

	return result.Templates, nil
}

// AnalyzeExpressionStyle åˆ†æè¡¨è¾¾é£æ ¼
func (c *TALClient) AnalyzeExpressionStyle(ctx context.Context, personName string, sampleText string) (*StyleAnalysis, error) {
	model := c.GetModelForTask("advanced_reasoning")

	prompt := fmt.Sprintf(`è¯·åˆ†æ%sçš„è¡¨è¾¾é£æ ¼ï¼š

æ ·æœ¬æ–‡æœ¬ï¼š%s

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œåˆ†æï¼š
1. è¯­è¨€ç‰¹ç‚¹ï¼ˆè¯æ±‡ã€å¥å¼ã€ä¿®è¾æ‰‹æ³•ï¼‰
2. æ€ç»´æ¨¡å¼ï¼ˆé€»è¾‘ç»“æ„ã€è®ºè¯æ–¹å¼ï¼‰
3. æ²Ÿé€šç­–ç•¥ï¼ˆç«‹åœºè¡¨è¾¾ã€å†²çªå¤„ç†ï¼‰
4. ä¸ªäººç‰¹è‰²ï¼ˆç‹¬ç‰¹æ ‡è¯†ã€é£æ ¼æ ‡ç­¾ï¼‰

è¯·è¿”å›JSONæ ¼å¼çš„åˆ†æç»“æœã€‚`, personName, sampleText)

	req := openai.ChatCompletionRequest{
		Model: model,
		Messages: []openai.ChatCompletionMessage{
			{
				Role:    openai.ChatMessageRoleUser,
				Content: prompt,
			},
		},
		MaxTokens:   c.config.MaxTokens,
		Temperature: c.config.Temperature,
	}

	resp, err := c.client.CreateChatCompletion(ctx, req)
	if err != nil {
		return getDefaultStyleAnalysis(), nil
	}

	if len(resp.Choices) == 0 {
		return getDefaultStyleAnalysis(), nil
	}

	content := resp.Choices[0].Message.Content

	var result StyleAnalysis
	jsonContent := content
	if strings.Contains(content, "```json") {
		startIndex := strings.Index(content, "```json")
		if startIndex != -1 {
			startIndex += 7
			endIndex := strings.Index(content[startIndex:], "```")
			if endIndex != -1 {
				jsonContent = strings.TrimSpace(content[startIndex : startIndex+endIndex])
			}
		}
	}

	if err := json.Unmarshal([]byte(jsonContent), &result); err != nil {
		return getDefaultStyleAnalysis(), nil
	}

	return &result, nil
}

// SimulateDebate æ¨¡æ‹Ÿè¾©è®º
func (c *TALClient) SimulateDebate(ctx context.Context, scenario string, difficulty int, userStyle string) (*DebateSimulation, error) {
	model := c.GetModelForTask("advanced_reasoning")

	prompt := fmt.Sprintf(`è¯·æ¨¡æ‹Ÿä¸€ä¸ª%såœºæ™¯çš„è¾©è®ºè®­ç»ƒï¼š

åœºæ™¯ï¼š%s
éš¾åº¦ç­‰çº§ï¼š%d
ç”¨æˆ·é£æ ¼ï¼š%s

è¯·ç”Ÿæˆï¼š
1. å¯¹æ‰‹çš„å¼€åœºé™ˆè¿°
2. 3è½®äº¤äº’å¯¹è¯
3. å…³é”®çš„ååº”æœºä¼šç‚¹
4. é£æ ¼é€‚é…å»ºè®®

è¿”å›JSONæ ¼å¼çš„ç»“æœã€‚`, scenario, scenario, difficulty, userStyle)

	req := openai.ChatCompletionRequest{
		Model: model,
		Messages: []openai.ChatCompletionMessage{
			{
				Role:    openai.ChatMessageRoleUser,
				Content: prompt,
			},
		},
		MaxTokens:   c.config.MaxTokens,
		Temperature: c.config.Temperature,
	}

	resp, err := c.client.CreateChatCompletion(ctx, req)
	if err != nil {
		return getDefaultDebateSimulation(), nil
	}

	if len(resp.Choices) == 0 {
		return getDefaultDebateSimulation(), nil
	}

	content := resp.Choices[0].Message.Content

	var result DebateSimulation
	jsonContent := content
	if strings.Contains(content, "```json") {
		startIndex := strings.Index(content, "```json")
		if startIndex != -1 {
			startIndex += 7
			endIndex := strings.Index(content[startIndex:], "```")
			if endIndex != -1 {
				jsonContent = strings.TrimSpace(content[startIndex : startIndex+endIndex])
			}
		}
	}

	if err := json.Unmarshal([]byte(jsonContent), &result); err != nil {
		return getDefaultDebateSimulation(), nil
	}

	return &result, nil
}

// GenerateResponseWithModel ä½¿ç”¨æŒ‡å®šæ¨¡å‹ç”Ÿæˆå›ç­”
func (c *TALClient) GenerateResponseWithModel(ctx context.Context, prompt, model string) (string, error) {
	// æ‰“å°è¾“å…¥ä¿¡æ¯
	fmt.Printf("ğŸ“ AIæ¨ç†è¾“å…¥:\n")
	fmt.Printf("   æ¨¡å‹: %s\n", model)
	fmt.Printf("   æç¤ºé•¿åº¦: %d å­—ç¬¦\n", len(prompt))
	if len(prompt) > 200 {
		fmt.Printf("   æç¤ºé¢„è§ˆ: %s...\n", prompt[:200])
	} else {
		fmt.Printf("   å®Œæ•´æç¤º: %s\n", prompt)
	}

	// è¯·æ±‚é™æµæ£€æŸ¥
	c.requestMutex.Lock()
	elapsed := time.Since(c.lastRequestTime)
	if elapsed < c.minInterval {
		waitTime := c.minInterval - elapsed
		fmt.Printf("â³ è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œç­‰å¾… %.2f ç§’...\n", waitTime.Seconds())
		time.Sleep(waitTime)
	}
	c.lastRequestTime = time.Now()
	c.requestMutex.Unlock()

	// æ„å»ºOpenAIå…¼å®¹çš„è¯·æ±‚
	requestBody := map[string]interface{}{
		"model": model,
		"messages": []map[string]string{
			{
				"role":    "user",
				"content": prompt,
			},
		},
		"max_tokens":  c.config.MaxTokens,
		"temperature": c.config.Temperature,
	}

	jsonData, err := json.Marshal(requestBody)
	if err != nil {
		return "", fmt.Errorf("æ„å»ºè¯·æ±‚å¤±è´¥: %w", err)
	}

	// åˆ›å»ºHTTPè¯·æ±‚
	url := fmt.Sprintf("%s/chat/completions", c.baseURL)
	req, err := http.NewRequestWithContext(ctx, "POST", url, bytes.NewBuffer(jsonData))
	if err != nil {
		return "", fmt.Errorf("åˆ›å»ºè¯·æ±‚å¤±è´¥: %w", err)
	}

	// è®¾ç½®è¯·æ±‚å¤´
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", fmt.Sprintf("Bearer %s", c.authToken))

	// å‘é€è¯·æ±‚ï¼ˆå¸¦è¶…æ—¶ç›‘æ§ï¼‰
	fmt.Printf("ğŸ”„ å‘é€AIè¯·æ±‚åˆ°: %s, æ¨¡å‹: %s, æç¤ºé•¿åº¦: %d\n", url, model, len(prompt))
	fmt.Printf("â³ å‘é€HTTPè¯·æ±‚ï¼Œç­‰å¾…å“åº”...\n")
	startTime := time.Now()
	resp, err := c.httpClient.Do(req)
	duration := time.Since(startTime)

	if err != nil {
		fmt.Printf("âŒ HTTPè¯·æ±‚å¤±è´¥ï¼Œè€—æ—¶: %.2fs, é”™è¯¯: %v\n", duration.Seconds(), err)

		// æ£€æŸ¥æ˜¯å¦æ˜¯è¶…æ—¶é”™è¯¯
		if strings.Contains(err.Error(), "context deadline exceeded") ||
		   strings.Contains(err.Error(), "Client.Timeout exceeded") {
			fmt.Println("ğŸ’¡ è¶…æ—¶å»ºè®®: AIæ¨ç†å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–å¢åŠ è¶…æ—¶è®¾ç½®")
		}

		return "", fmt.Errorf("å‘é€è¯·æ±‚å¤±è´¥: %w", err)
	}

	fmt.Printf("âœ… HTTPè¯·æ±‚æˆåŠŸï¼Œè€—æ—¶: %.2fs\n", duration.Seconds())
	defer resp.Body.Close()

	// è¯»å–å“åº”
	body, err := io.ReadAll(resp.Body)
	if err != nil {
		fmt.Printf("âŒ AIå“åº”è¯»å–å¤±è´¥: %v\n", err)
		return "", fmt.Errorf("è¯»å–å“åº”å¤±è´¥: %w", err)
	}

	fmt.Printf("ğŸ“¡ AIå“åº”çŠ¶æ€ç : %d, å“åº”å¤§å°: %d bytes\n", resp.StatusCode, len(body))

	if resp.StatusCode != http.StatusOK {
		// ç‰¹æ®Šå¤„ç†429é”™è¯¯ï¼ˆé…é¢è¶…é™ï¼‰
		if resp.StatusCode == 429 {
			fmt.Printf("âš ï¸ AIæœåŠ¡é…é¢è¶…é™ (429): %s\n", string(body))
			fmt.Println("ğŸ’¡ å»ºè®®: æ£€æŸ¥APIé…é¢ã€é™ä½è¯·æ±‚é¢‘ç‡æˆ–è”ç³»æœåŠ¡å•†")

			// å°è¯•ç­‰å¾…åé‡è¯•ä¸€æ¬¡
			fmt.Println("ğŸ”„ ç­‰å¾…5ç§’åé‡è¯•...")
			time.Sleep(5 * time.Second)

			// é‡ç½®é™æµæ—¶é—´æˆ³ä»¥å…è®¸é‡è¯•
			c.requestMutex.Lock()
			c.lastRequestTime = time.Now().Add(-c.minInterval)
			c.requestMutex.Unlock()

			// é€’å½’é‡è¯•ä¸€æ¬¡
			return c.GenerateResponseWithModel(ctx, prompt, model)
		} else {
			fmt.Printf("âŒ AIæœåŠ¡é”™è¯¯ (çŠ¶æ€ç : %d): %s\n", resp.StatusCode, string(body))
		}
		return "", fmt.Errorf("AIæœåŠ¡è¿”å›é”™è¯¯çŠ¶æ€ç : %d, å“åº”: %s", resp.StatusCode, string(body))
	}

	fmt.Println("âœ… AIè¯·æ±‚æˆåŠŸ")

	// è§£æå“åº”
	var response map[string]interface{}
	if err := json.Unmarshal(body, &response); err != nil {
		return "", fmt.Errorf("è§£æå“åº”å¤±è´¥: %w", err)
	}

	// æå–å›ç­”å†…å®¹
	choices, ok := response["choices"].([]interface{})
	if !ok || len(choices) == 0 {
		return "", fmt.Errorf("å“åº”ä¸­æ²¡æœ‰æ‰¾åˆ°choiceså­—æ®µæˆ–ä¸ºç©º")
	}

	choice, ok := choices[0].(map[string]interface{})
	if !ok {
		return "", fmt.Errorf("choiceæ ¼å¼ä¸æ­£ç¡®")
	}

	message, ok := choice["message"].(map[string]interface{})
	if !ok {
		return "", fmt.Errorf("messageæ ¼å¼ä¸æ­£ç¡®")
	}

	content, ok := message["content"].(string)
	if !ok {
		return "", fmt.Errorf("contentå­—æ®µä¸å­˜åœ¨æˆ–ä¸æ˜¯å­—ç¬¦ä¸²")
	}

	// æ‰“å°è¾“å‡ºä¿¡æ¯
	fmt.Printf("ğŸ“¤ AIæ¨ç†è¾“å‡º:\n")
	fmt.Printf("   å“åº”é•¿åº¦: %d å­—ç¬¦\n", len(content))
	if len(content) > 200 {
		fmt.Printf("   å“åº”é¢„è§ˆ: %s...\n", content[:200])
	} else {
		fmt.Printf("   å®Œæ•´å“åº”: %s\n", content)
	}

	return content, nil
}

// EvaluateReaction è¯„ä¼°ååº”
func (c *TALClient) EvaluateReaction(ctx context.Context, userResponse, scenario, expectedStyle string) (*ReactionEvaluation, error) {
	model := c.GetModelForTask("advanced_reasoning")

	prompt := fmt.Sprintf(`è¯·è¯„ä¼°ç”¨æˆ·çš„ååº”è¡¨ç°ï¼š

ç”¨æˆ·ååº”ï¼š%s
åœºæ™¯ï¼š%s
æœŸæœ›é£æ ¼ï¼š%s

è¯·ä»ä»¥ä¸‹ç»´åº¦è¯„ä¼°ï¼š
1. å†…å®¹è´¨é‡ï¼ˆé€»è¾‘æ€§ã€ç›¸å…³æ€§ï¼‰
2. é£æ ¼ç¬¦åˆåº¦ï¼ˆæ˜¯å¦ç¬¦åˆæœŸæœ›é£æ ¼ï¼‰
3. ååº”é€Ÿåº¦ï¼ˆæ€è€ƒ-ååº”çš„æ—¶é—´åˆç†æ€§ï¼‰
4. æ²Ÿé€šæ•ˆæœï¼ˆè¯´æœåŠ›ã€æ„ŸæŸ“åŠ›ï¼‰
5. æ”¹è¿›å»ºè®®

è¿”å›JSONæ ¼å¼çš„è¯„ä¼°ç»“æœã€‚`, userResponse, scenario, expectedStyle)

	req := openai.ChatCompletionRequest{
		Model: model,
		Messages: []openai.ChatCompletionMessage{
			{
				Role:    openai.ChatMessageRoleUser,
				Content: prompt,
			},
		},
		MaxTokens:   c.config.MaxTokens,
		Temperature: c.config.Temperature,
	}

	resp, err := c.client.CreateChatCompletion(ctx, req)
	if err != nil {
		return getDefaultReactionEvaluation(), nil
	}

	if len(resp.Choices) == 0 {
		return getDefaultReactionEvaluation(), nil
	}

	content := resp.Choices[0].Message.Content

	var result ReactionEvaluation
	jsonContent := content
	if strings.Contains(content, "```json") {
		startIndex := strings.Index(content, "```json")
		if startIndex != -1 {
			startIndex += 7
			endIndex := strings.Index(content[startIndex:], "```")
			if endIndex != -1 {
				jsonContent = strings.TrimSpace(content[startIndex : startIndex+endIndex])
			}
		}
	}

	if err := json.Unmarshal([]byte(jsonContent), &result); err != nil {
		return getDefaultReactionEvaluation(), nil
	}

	return &result, nil
}
